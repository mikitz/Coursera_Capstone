{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# Captsone project for the IBM Data Science Professional Certificate \n\n(https://www.coursera.org/professional-certificates/ibm-data-science?#courses)"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Hello, Capstone Project Course!\n"
                }
            ],
            "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nprint(\"Hello, Capstone Project Course!\")"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Solving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/Python36\n\n  added / updated specs: \n    - seaborn\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2020.7.22  |                0         132 KB  anaconda\n    seaborn-0.10.1             |             py_0         160 KB  anaconda\n    certifi-2020.6.20          |           py36_0         160 KB  anaconda\n    openssl-1.1.1g             |       h7b6447c_0         3.8 MB  anaconda\n    ------------------------------------------------------------\n                                           Total:         4.2 MB\n\nThe following packages will be UPDATED:\n\n    ca-certificates: 2020.7.22-0        --> 2020.7.22-0       anaconda\n    certifi:         2020.6.20-py36_0   --> 2020.6.20-py36_0  anaconda\n    openssl:         1.1.1g-h7b6447c_0  --> 1.1.1g-h7b6447c_0 anaconda\n    seaborn:         0.9.0-pyh91ea838_1 --> 0.10.1-py_0       anaconda\n\n\nDownloading and Extracting Packages\nca-certificates-2020 | 132 KB    | ##################################### | 100% \nseaborn-0.10.1       | 160 KB    | ##################################### | 100% \ncertifi-2020.6.20    | 160 KB    | ##################################### | 100% \nopenssl-1.1.1g       | 3.8 MB    | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nSeaborn installed successfully!\n"
                }
            ],
            "source": "!conda install -c anaconda seaborn -y\nimport seaborn as sb\nprint(\"Seaborn installed successfully!\")"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "CSV read into dataframe\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n"
                }
            ],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2. Data Acquisition and Cleaning"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "Index(['SEVERITYCODE', 'X', 'Y', 'OBJECTID', 'INCKEY', 'COLDETKEY', 'REPORTNO',\n       'ADDRTYPE', 'LOCATION', 'SEVERITYCODE.1', 'SEVERITYDESC',\n       'COLLISIONTYPE', 'PERSONCOUNT', 'PEDCOUNT', 'PEDCYLCOUNT', 'VEHCOUNT',\n       'INCDATE', 'INCDTTM', 'JUNCTIONTYPE', 'SDOT_COLCODE', 'SDOT_COLDESC',\n       'UNDERINFL', 'WEATHER', 'ROADCOND', 'LIGHTCOND', 'SDOTCOLNUM',\n       'ST_COLCODE', 'ST_COLDESC', 'SEGLANEKEY', 'CROSSWALKKEY',\n       'HITPARKEDCAR'],\n      dtype='object')"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# drop the column of PEDROWNOTGRNT due to missing 97.6% of values and drop SPEEDING due to too many missing values.\n# drop INTKEY, INATTENTIONIND, and STATUS due to irrelevance.\ndfw = df.drop(['PEDROWNOTGRNT', 'INTKEY', 'INATTENTIONIND', 'SPEEDING', 'STATUS'], axis = 1)\n# drop the rows containing NaN values for the following columns.\ndfw.dropna(subset=['X', 'Y', 'ADDRTYPE', 'LOCATION', 'COLLISIONTYPE', 'JUNCTIONTYPE', 'UNDERINFL', 'WEATHER', 'ROADCOND', 'LIGHTCOND', 'ST_COLDESC', 'SDOTCOLNUM'], axis = 0, inplace = True)\n# drop EXCEPTRSNCODE and EXCEPTRSNDESC columns as missing 96.46% and 99.99% of values respectively\ndfw.drop(['EXCEPTRSNCODE', 'EXCEPTRSNDESC'], axis = 1, inplace = True)\ndfw.columns"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "# create a new dataframe on which to run the models\ndfm = dfw.drop(['OBJECTID', 'INCKEY', 'COLDETKEY', 'REPORTNO', 'LOCATION', 'SEVERITYDESC', 'INCDATE', 'INCDTTM', 'SDOTCOLNUM', 'SEGLANEKEY', 'CROSSWALKKEY', 'HITPARKEDCAR', 'ST_COLCODE', 'ST_COLDESC', 'SDOT_COLDESC', 'SDOT_COLCODE', 'ADDRTYPE', 'UNDERINFL'], axis = 1)"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "ename": "KeyError",
                    "evalue": "\"['X' 'Y'] not found in axis\"",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-11-fa6850287703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# drop the pesky X and Y columns... Finally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# drop the duplicate SEVERITYCODE column named SEVERITYCODE.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SEVERITYCODE.1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3940\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3779\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3780\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4962\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4963\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4964\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4965\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4966\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyError\u001b[0m: \"['X' 'Y'] not found in axis\""
                    ]
                }
            ],
            "source": "# drop the pesky X and Y columns... Finally\ndfm.drop(['X', 'Y'], axis = 1, inplace = True)\n# drop the duplicate SEVERITYCODE column named SEVERITYCODE.1\ndfm.drop(['SEVERITYCODE.1'], axis = 1, inplace = True)\ndfm.shape"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(109264, 10)"
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# filter out the rows in which there are more than 10 persons.\ndfm1 = dfm[dfm['PERSONCOUNT'] < 11]\ndfm1.shape"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(109260, 10)"
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# filter out the rows in which there are more than 3 pedestrians. \ndfm2 = dfm1[dfm1['PEDCOUNT'] < 4]\ndfm2.shape"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "PERSONCOUNT  SEVERITYCODE\n0            1                 171\n             2                  70\n1            1                4654\n             2                1603\n2            1               50072\n             2               15860\n3            1               13078\n             2                7975\n4            1                5048\n             2                3781\n5            1                2213\n             2                1836\n6            1                 845\n             2                 841\n7            1                 287\n             2                 394\n8            1                 150\n             2                 175\n9            1                  51\n             2                  76\n10           1                  32\n             2                  48\nName: SEVERITYCODE, dtype: int64"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "dfm2.groupby(['PERSONCOUNT', 'SEVERITYCODE'])['SEVERITYCODE'].count()"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "Index(['SEVERITYCODE', 'COLLISIONTYPE', 'PERSONCOUNT', 'PEDCOUNT',\n       'PEDCYLCOUNT', 'VEHCOUNT', 'JUNCTIONTYPE', 'WEATHER', 'ROADCOND',\n       'LIGHTCOND'],\n      dtype='object')"
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "dfm2.columns"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "SEVERITYCODE     0\nCOLLISIONTYPE    0\nPERSONCOUNT      0\nPEDCOUNT         0\nPEDCYLCOUNT      0\nVEHCOUNT         0\nJUNCTIONTYPE     0\nWEATHER          0\nROADCOND         0\nLIGHTCOND        0\ndtype: int64"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "dfm2.isnull().sum()"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SEVERITYCODE</th>\n      <th>COLLISIONTYPE</th>\n      <th>PERSONCOUNT</th>\n      <th>PEDCOUNT</th>\n      <th>PEDCYLCOUNT</th>\n      <th>VEHCOUNT</th>\n      <th>JUNCTIONTYPE</th>\n      <th>WEATHER</th>\n      <th>ROADCOND</th>\n      <th>LIGHTCOND</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Sideswipe</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Mid-Block (not related to intersection)</td>\n      <td>Raining</td>\n      <td>Wet</td>\n      <td>Dark - Street Lights On</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Parked Car</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Mid-Block (not related to intersection)</td>\n      <td>Overcast</td>\n      <td>Dry</td>\n      <td>Daylight</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Angles</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>At Intersection (intersection related)</td>\n      <td>Raining</td>\n      <td>Wet</td>\n      <td>Daylight</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>Angles</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>At Intersection (intersection related)</td>\n      <td>Raining</td>\n      <td>Wet</td>\n      <td>Daylight</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>Parked Car</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Mid-Block (not related to intersection)</td>\n      <td>Clear</td>\n      <td>Dry</td>\n      <td>Daylight</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   SEVERITYCODE COLLISIONTYPE  PERSONCOUNT  PEDCOUNT  PEDCYLCOUNT  VEHCOUNT  \\\n1             1     Sideswipe            2         0            0         2   \n2             1    Parked Car            4         0            0         3   \n4             2        Angles            2         0            0         2   \n6             1        Angles            2         0            0         2   \n8             1    Parked Car            2         0            0         2   \n\n                              JUNCTIONTYPE   WEATHER ROADCOND  \\\n1  Mid-Block (not related to intersection)   Raining      Wet   \n2  Mid-Block (not related to intersection)  Overcast      Dry   \n4   At Intersection (intersection related)   Raining      Wet   \n6   At Intersection (intersection related)   Raining      Wet   \n8  Mid-Block (not related to intersection)     Clear      Dry   \n\n                 LIGHTCOND  \n1  Dark - Street Lights On  \n2                 Daylight  \n4                 Daylight  \n6                 Daylight  \n8                 Daylight  "
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "dfm2.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 3. Exploratory Data Analysis"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# 3.2 plot severity vs lighting conditions\nplt.style.use('ggplot')\nplt.figure(figsize = (20, 10))\nax = sb.countplot(y = \"LIGHTCOND\", hue = \"SEVERITYCODE\", data = dfm2)\nplt.title('Lighting Conditions vs. Number of Collisions by Severity', fontsize = 30)\nplt.xlabel('Number of Collisions', fontsize = 24)\nplt.ylabel('Lighting Conditions', fontsize = 24)\nplt.tick_params(labelsize=18);\nplt.legend(fontsize = 18, title = \"Severity\", loc = 'lower right')\nplt.text(0, 8.7, \"Figure 2: Lighting conditions plotted against the number of collisions grouped by severity\", fontsize = 16)\n\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy()\n    ax.annotate(int(width),\n                ((x + width), y + height/2),\n                fontsize = 18, \n                textcoords = 'offset points',\n                xytext = (50, 0),\n                color = '#000000',\n                ha = 'right',\n                va = 'center')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# 3.3 plot severity vs weather conditions\nplt.style.use('ggplot')\nplt.figure(figsize = (20, 10))\nax = sb.countplot(y = \"WEATHER\", hue = \"SEVERITYCODE\", data = dfm2)\nplt.title('Weather Conditions vs. Number of Collisions by Severity', fontsize = 30)\nplt.xlabel('Number of Collisions', fontsize = 24)\nplt.ylabel('Weather Conditions', fontsize = 24)\nplt.tick_params(labelsize=18);\nplt.legend(fontsize = 18, title = \"Severity\", loc = 'lower right')\nplt.text(0, 11, \"Figure 3: Weather conditions plotted against the number of collisions grouped by severity\", fontsize = 16)\n\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy()\n    ax.annotate(int(width),\n                ((x + width), y + height/2),\n                fontsize = 18, \n                textcoords = 'offset points',\n                xytext = (50, 0),\n                color = '#000000',\n                ha = 'right',\n                va = 'center')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# 3.4 plot severity vs road conditions\nplt.style.use('ggplot')\nplt.figure(figsize = (20, 10))\nax = sb.countplot(y = \"ROADCOND\", hue = \"SEVERITYCODE\", data = dfm2)\nplt.title('Road Conditions vs. Number of Collisions by Severity', fontsize = 30)\nplt.xlabel('Number of Collisions', fontsize = 24)\nplt.ylabel('Road Conditions', fontsize = 24)\nplt.tick_params(labelsize=18);\nplt.legend(fontsize = 18, title = \"Severity\", loc = 'lower right')\nplt.text(0, 10, \"Figure 4: Road conditions plotted against the number of collisions grouped by severity\", fontsize = 16)\n\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy()\n    ax.annotate(int(width),\n                ((x + width), y + height/2),\n                fontsize = 18, \n                textcoords = 'offset points',\n                xytext = (50, 0),\n                color = '#000000',\n                ha = 'right',\n                va = 'center')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# 3.5 plot severity vs collision type\nplt.style.use('ggplot')\nplt.figure(figsize = (20, 10))\nax = sb.countplot(y = \"COLLISIONTYPE\", hue = \"SEVERITYCODE\", data = dfm2)\nplt.title('Collision Type vs. Number of Collisions by Severity', fontsize = 30)\nplt.xlabel('Number of Collisions', fontsize = 24)\nplt.ylabel('Collision Type', fontsize = 24)\nplt.tick_params(labelsize=18);\nplt.legend(fontsize = 18, title = \"Severity\", loc = 'lower right')\nplt.text(0, 11, \"Figure 5: Collision type plotted against the number of collisions grouped by severity\", fontsize = 16)\n\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy()\n    ax.annotate(int(width),\n                ((x + width), y + height/2),\n                fontsize = 18, \n                textcoords = 'offset points',\n                xytext = (50, 0),\n                color = '#000000',\n                ha = 'right',\n                va = 'center')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# 3.6 plot severity vs junction type\nplt.style.use('ggplot')\nplt.figure(figsize = (20, 10))\nax = sb.countplot(y = \"JUNCTIONTYPE\", hue = \"SEVERITYCODE\", data = dfm2)\nplt.title('Junction Type vs. Number of Collisions by Severity', fontsize = 30)\nplt.xlabel('Number of Collisions', fontsize = 24)\nplt.ylabel('Junction Type', fontsize = 24)\nplt.tick_params(labelsize=18);\nplt.legend(fontsize = 18, title = \"Severity\", loc = 'lower right')\nplt.text(0, 6.5, \"Figure 6: Junction type plotted against the number of collisions grouped by severity\", fontsize = 16)\n\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy()\n    ax.annotate(int(width),\n                ((x + width), y + height/2),\n                fontsize = 18, \n                textcoords = 'offset points',\n                xytext = (50, 0),\n                color = '#000000',\n                ha = 'right',\n                va = 'center')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# 3.7.1 plot severity vs number of vehicles between 1 and 3\ndfvc = dfm2.loc[(dfm2['VEHCOUNT'] > 0) & (dfm2['VEHCOUNT'] < 4)]\nplt.style.use('ggplot')\nplt.figure(figsize = (20, 10))\nax = sb.countplot(y = \"VEHCOUNT\", hue = \"SEVERITYCODE\", data = dfvc)\nplt.title('Number of Vehicles vs. Number of Collisions by Severity', fontsize = 30)\nplt.xlabel('Number of Collisions', fontsize = 24)\nplt.ylabel('Number of Vehicles', fontsize = 24)\nplt.tick_params(labelsize=18);\nplt.legend(fontsize = 18, title = \"Severity\", loc = 'lower right')\nplt.text(0, 3, \"Figure 7.1: Number of vehicles type plotted against the number of collisions grouped by severity\", fontsize = 16)\n\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy()\n    ax.annotate(int(width),\n                ((x + width), y + height/2),\n                fontsize = 18, \n                textcoords = 'offset points',\n                xytext = (50, 0),\n                color = '#000000',\n                ha = 'right',\n                va = 'center')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# 3.7.2 plot severity vs number of vehicles between 4 and 6\ndfvc = dfm2.loc[(dfm2['VEHCOUNT'] > 3) & (dfm2['VEHCOUNT'] < 7)]\nplt.style.use('ggplot')\nplt.figure(figsize = (20, 10))\nax = sb.countplot(y = \"VEHCOUNT\", hue = \"SEVERITYCODE\", data = dfvc)\nplt.title('Number of Vehicles vs. Number of Collisions by Severity', fontsize = 30)\nplt.xlabel('Number of Collisions', fontsize = 24)\nplt.ylabel('Number of Vehicles', fontsize = 24)\nplt.tick_params(labelsize=18);\nplt.legend(fontsize = 18, title = \"Severity\", loc = 'lower right')\nplt.text(0, 3, \"Figure 7.2: Number of vehicles type plotted against the number of collisions grouped by severity\", fontsize = 16)\n\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy()\n    ax.annotate(int(width),\n                ((x + width), y + height/2),\n                fontsize = 18, \n                textcoords = 'offset points',\n                xytext = (40, 0),\n                color = '#000000',\n                ha = 'right',\n                va = 'center')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# 3.7.3 plot severity vs number of vehicles between 7 and 11\ndfvc = dfm2.loc[(dfm2['VEHCOUNT'] > 6) & (dfm2['VEHCOUNT'] < 12)]\nplt.style.use('ggplot')\nplt.figure(figsize = (20, 10))\nax = sb.countplot(y = \"VEHCOUNT\", hue = \"SEVERITYCODE\", data = dfvc)\nplt.title('Number of Vehicles vs. Number of Collisions by Severity', fontsize = 30)\nplt.xlabel('Number of Collisions', fontsize = 24)\nplt.ylabel('Number of Vehicles', fontsize = 24)\nplt.tick_params(labelsize=18);\nplt.legend(fontsize = 18, title = \"Severity\", loc = 'lower right')\nplt.text(0, 5.4, \"Figure 7.3: Number of vehicles type plotted against the number of collisions grouped by severity\", fontsize = 16)\n\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy()\n    if np.isnan(width):\n        continue\n    ax.annotate(int(width),\n                ((x + width), y + height/2),\n                fontsize = 18, \n                textcoords = 'offset points',\n                xytext = (20, 0),\n                color = '#000000',\n                ha = 'right',\n                va = 'center')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# 3.8 plot severity vs number of people \nplt.style.use('ggplot')\nplt.figure(figsize = (20, 10))\nax = sb.countplot(y = \"PERSONCOUNT\", hue = \"SEVERITYCODE\", data = dfm2)\nplt.title('Number of People vs. Number of Collisions by Severity', fontsize = 30)\nplt.xlabel('Number of Collisions', fontsize = 24)\nplt.ylabel('Number of People', fontsize = 24)\nplt.tick_params(labelsize=18);\nplt.legend(fontsize = 18, title = \"Severity\", loc = 'lower right')\nplt.text(0, 12, \"Figure 8: Number of people plotted against the number of collisions grouped by severity\", fontsize = 16)\n\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy()\n    ax.annotate(int(width),\n                ((x + width), y + height/2),\n                fontsize = 18, \n                textcoords = 'offset points',\n                xytext = (50, 0),\n                color = '#000000',\n                ha = 'right',\n                va = 'center')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# 3.9 plot severity vs number of pedestrians\nplt.style.use('ggplot')\nplt.figure(figsize = (20, 10))\nax = sb.countplot(y = \"PEDCOUNT\", hue = \"SEVERITYCODE\", data = dfm2)\nplt.title('Number of Pedestrians vs. Number of Collisions by Severity', fontsize = 30)\nplt.xlabel('Number of Collisions', fontsize = 24)\nplt.ylabel('Number of Pedestrians', fontsize = 24)\nplt.tick_params(labelsize=18);\nplt.legend(fontsize = 18, title = \"Severity\", loc = 'lower right')\nplt.text(0, 4, \"Figure 9: Number of pedestrians plotted against the number of collisions grouped by severity\", fontsize = 16)\n\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy()\n    if np.isnan(width):\n        continue\n    ax.annotate(int(width),\n                ((x + width), y + height/2),\n                fontsize = 18, \n                textcoords = 'offset points',\n                xytext = (50, 0),\n                color = '#000000',\n                ha = 'right',\n                va = 'center')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "dfm2.dtypes\ndfm2.columns"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 4. Predictive Modeling"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 4.1 Data Wrangling"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": "# Converting categorical variables to quantitative variables\ndummy_collisiontype = pd.get_dummies(dfm2[\"COLLISIONTYPE\"])\ndummy_junctiontype  = pd.get_dummies(dfm2[\"JUNCTIONTYPE\"])\ndummy_weather = pd.get_dummies(dfm2[\"WEATHER\"])\ndummy_roadcond = pd.get_dummies(dfm2[\"ROADCOND\"])\ndummy_lightcond = pd.get_dummies(dfm2[\"LIGHTCOND\"])"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": "# merging data from dummies into the dataframe\ndfm3 = pd.concat([dfm2, dummy_collisiontype], axis = 1)\ndfm3 = pd.concat([dfm3, dummy_junctiontype], axis = 1)\ndfm3 = pd.concat([dfm3, dummy_weather], axis = 1)\ndfm3 = pd.concat([dfm3, dummy_roadcond], axis = 1)\ndfm3 = pd.concat([dfm3, dummy_lightcond], axis = 1)"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(109260, 48)"
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# dropping original categorical variable columns\ndfm3.drop(\"COLLISIONTYPE\", axis = 1, inplace = True)\ndfm3.drop(\"JUNCTIONTYPE\", axis = 1, inplace = True)\ndfm3.drop(\"WEATHER\", axis = 1, inplace = True)\ndfm3.drop(\"ROADCOND\", axis = 1, inplace = True)\ndfm3.drop(\"LIGHTCOND\", axis = 1, inplace = True)\n\ndfm3.shape"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "Index(['SEVERITYCODE', 'PERSONCOUNT', 'PEDCOUNT', 'PEDCYLCOUNT', 'VEHCOUNT',\n       'Angles', 'Cycles', 'Head On', 'Left Turn', 'Other', 'Parked Car',\n       'Pedestrian', 'Rear Ended', 'Right Turn', 'Sideswipe',\n       'At Intersection (but not related to intersection)',\n       'At Intersection (intersection related)', 'Driveway Junction',\n       'Mid-Block (but intersection related)',\n       'Mid-Block (not related to intersection)', 'Ramp Junction',\n       'Blowing Sand/Dirt', 'Clear', 'Fog/Smog/Smoke', 'Other', 'Overcast',\n       'Raining', 'Severe Crosswind', 'Sleet/Hail/Freezing Rain', 'Snowing',\n       'Unknown', 'Dry', 'Ice', 'Oil', 'Other', 'Sand/Mud/Dirt', 'Snow/Slush',\n       'Standing Water', 'Unknown', 'Wet', 'Dark - No Street Lights',\n       'Dark - Street Lights Off', 'Dark - Street Lights On', 'Dawn',\n       'Daylight', 'Dusk', 'Other', 'Unknown'],\n      dtype='object')"
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "dfm3.columns"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "Index(['SEVERITYCODE', 'PERSONCOUNT', 'PEDCOUNT', 'PEDCYLCOUNT', 'VEHCOUNT',\n       'ANGLES', 'CYCLES', 'HEAD ON', 'LEFT TURN', 'OTHER', 'PARKED CAR',\n       'PEDESTRIAN', 'REAR ENDED', 'RIGHT TURN', 'SIDESWIPE',\n       'AT INTERSECTION (BUT NOT RELATED TO INTERSECTION)',\n       'AT INTERSECTION (INTERSECTION RELATED)', 'DRIVEWAY JUNCTION',\n       'MID-BLOCK (BUT INTERSECTION RELATED)',\n       'MID-BLOCK (NOT RELATED TO INTERSECTION)', 'RAMP JUNCTION',\n       'BLOWING SAND/DIRT', 'CLEAR', 'FOG/SMOG/SMOKE', 'OTHER', 'OVERCAST',\n       'RAINING', 'SEVERE CROSSWIND', 'SLEET/HAIL/FREEZING RAIN', 'SNOWING',\n       'UNKNOWN', 'DRY', 'ICE', 'OIL', 'OTHER', 'SAND/MUD/DIRT', 'SNOW/SLUSH',\n       'STANDING WATER', 'UNKNOWN', 'WET', 'DARK - NO STREET LIGHTS',\n       'DARK - STREET LIGHTS OFF', 'DARK - STREET LIGHTS ON', 'DAWN',\n       'DAYLIGHT', 'DUSK', 'OTHER', 'UNKNOWN'],\n      dtype='object')"
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# convert all columns to uppercase for consistency\ndfm3.columns = map(str.upper, dfm3.columns)\ndfm3.columns"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 4.2 Regression Models"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import Ridge"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": "Z = dfm3[['PERSONCOUNT', 'PEDCOUNT', 'PEDCYLCOUNT', 'VEHCOUNT',\n       'ANGLES', 'CYCLES', 'HEAD ON', 'LEFT TURN', 'PARKED CAR',\n       'PEDESTRIAN', 'REAR ENDED', 'RIGHT TURN', 'SIDESWIPE',\n       'AT INTERSECTION (BUT NOT RELATED TO INTERSECTION)',\n       'AT INTERSECTION (INTERSECTION RELATED)', 'DRIVEWAY JUNCTION',\n       'MID-BLOCK (BUT INTERSECTION RELATED)',\n       'MID-BLOCK (NOT RELATED TO INTERSECTION)', 'RAMP JUNCTION',\n       'BLOWING SAND/DIRT', 'CLEAR', 'FOG/SMOG/SMOKE', 'OVERCAST',\n       'RAINING', 'SEVERE CROSSWIND', 'SLEET/HAIL/FREEZING RAIN', 'SNOWING',\n       'UNKNOWN', 'DRY', 'ICE', 'OIL', 'SAND/MUD/DIRT', 'SNOW/SLUSH',\n       'STANDING WATER', 'WET', 'DARK - NO STREET LIGHTS',\n       'DARK - STREET LIGHTS OFF', 'DARK - STREET LIGHTS ON', 'DAWN',\n       'DAYLIGHT', 'DUSK']]\nY = dfm3[['SEVERITYCODE']]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Multiple Linear Regression"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "LR = LinearRegression()\nLR.fit(Z, Y)\nprint(\"The intercept is: \", LR.intercept_)\nprint(\"The coefficients are: \", LR.coef_)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Yhat = LR.predict(Z)\nmse = mean_squared_error(dfm3['SEVERITYCODE'], Yhat)\nprint(\"the R-squared is: \", LR.score(Z, Y))\nprint(\"The MSE is: \", mse)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "plt.figure(figsize = (12, 10))\n\nax1 = sb.distplot(dfm3['SEVERITYCODE'], hist = False, color = \"green\", label = \"Actual Value\")\nsb.distplot(Yhat, hist = False, color = \"purple\", label = \"Fitted Values\", ax = ax1)\n\nplt.title('Actual vs. Fitted Values for Severity')\nplt.xlabel('Severity')\nplt.ylabel('Proportion of Collisions')\n\nplt.show()\nplt.close()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Polynomial Regression"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Input = [('scale',StandardScaler()), ('polynomial', PolynomialFeatures(include_bias=False)), ('model',LinearRegression())]\npipe = Pipeline(Input)\npipe.fit(Z, Y)\nypipe = pipe.predict(Z)\nypipe[0:4]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "mse = mean_squared_error(dfm3['SEVERITYCODE'], ypipe)\nprint(\"the R-squared is: \", LR.score(Z, Y))\nprint(\"The MSE is: \", mse)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "plt.figure(figsize = (12, 10))\n\nax1 = sb.distplot(dfm3['SEVERITYCODE'], hist = False, color = \"green\", label = \"Actual Value\")\nsb.distplot(ypipe, hist = False, color = \"purple\", label = \"Fitted Values\", ax = ax1)\n\nplt.title('Actual vs. Fitted Values for Severity')\nplt.xlabel('Severity')\nplt.ylabel('Proportion of Collisions')\n\nplt.show()\nplt.close()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Ridge Regression"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "x_train, x_test, y_train, y_test = train_test_split(Z, Y, test_size=0.15, random_state=1)\n\nprint(\"number of test samples :\", x_test.shape[0])\nprint(\"number of training samples:\",x_train.shape[0])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "pr=PolynomialFeatures(degree=2)\nx_train_pr=pr.fit_transform(x_train)\nx_test_pr=pr.fit_transform(x_test)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "RidgeModel = Ridge(alpha=0.1)\nRidgeModel.fit(x_train_pr, y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "yhat = RidgeModel.predict(x_test_pr)\nprint('predicted:', yhat[0:4])\nprint('test set :', y_test[0:4].values)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# select the alpha that minimizes the test error\nparameters1 = [{'alpha': [0.001, 0.01, 0.1,1, 10, 100, 1000, 10000, 100000]}]\nparameters1\nRR = Ridge()\nGrid1 = GridSearchCV(RR, parameters1, cv=4)\nGrid1.fit(Z, Y)\nBestRR = Grid1.best_estimator_\nprint(\"the R-squared is: \", BestRR.score(x_test, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "mse = mean_squared_error(y_test, yhat)\nprint(\"the MSE is: \", mse)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 4.3 Classification Models"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": "import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline\nfrom sklearn import metrics"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Z = preprocessing.StandardScaler().fit(Z).transform(Z.astype(float))\nZ[0:5]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "X_train, X_test, y_train, y_test = train_test_split(Z, Y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "np.mean([2, 3, 45, 5])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### K-Nearest Neighbor"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.neighbors import KNeighborsClassifier"
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train set Accuracy for  1  is:  0.7088138385502472\nTest set Accuracy for  1  is:  0.6810818231740802\nThe Average for the two scores is:  0.6949478308621637\n"
                }
            ],
            "source": "k = 1\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train.values.ravel())\nyhat = neigh.predict(X_test)\nyhat[0:5]\ntrain_score = metrics.accuracy_score(y_train, neigh.predict(X_train))\ntest_score = metrics.accuracy_score(y_test, yhat)\nprint(\"Train set Accuracy for \", k, \" is: \", train_score)\nprint(\"Test set Accuracy for \", k, \" is: \", test_score)\nprint(\"The Average for the two scores is: \", np.mean([train_score, test_score]))"
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train set Accuracy for  2  is:  0.7445428336079077\nTest set Accuracy for  2  is:  0.7277594728171335\nThe Average for the two scores is:  0.7361511532125207\n"
                }
            ],
            "source": "k = 2\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train.values.ravel())\nyhat = neigh.predict(X_test)\nyhat[0:5]\ntrain_score = metrics.accuracy_score(y_train, neigh.predict(X_train))\ntest_score = metrics.accuracy_score(y_test, yhat)\nprint(\"Train set Accuracy for \", k, \" is: \", train_score)\nprint(\"Test set Accuracy for \", k, \" is: \", test_score)\nprint(\"The Average for the two scores is: \", np.mean([train_score, test_score]))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "k = 3\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train.values.ravel())\nyhat = neigh.predict(X_test)\nyhat[0:5]\ntrain_score = metrics.accuracy_score(y_train, neigh.predict(X_train))\ntest_score = metrics.accuracy_score(y_test, yhat)\nprint(\"Train set Accuracy for \", k, \" is: \", train_score)\nprint(\"Test set Accuracy for \", k, \" is: \", test_score)\nprint(\"The Average for the two scores is: \", np.mean([train_score, test_score]))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "k = 4\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train.values.ravel())\nyhat = neigh.predict(X_test)\nyhat[0:5]\ntrain_score = metrics.accuracy_score(y_train, neigh.predict(X_train))\ntest_score = metrics.accuracy_score(y_test, yhat)\nprint(\"Train set Accuracy for \", k, \" is: \", train_score)\nprint(\"Test set Accuracy for \", k, \" is: \", test_score)\nprint(\"The Average for the two scores is: \", np.mean([train_score, test_score]))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "k = 5\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train.values.ravel())\nyhat = neigh.predict(X_test)\nyhat[0:5]\ntrain_score = metrics.accuracy_score(y_train, neigh.predict(X_train))\ntest_score = metrics.accuracy_score(y_test, yhat)\nprint(\"Train set Accuracy for \", k, \" is: \", train_score)\nprint(\"Test set Accuracy for \", k, \" is: \", test_score)\nprint(\"The Average for the two scores is: \", np.mean([train_score, test_score]))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "k = 6\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train.values.ravel())\nyhat = neigh.predict(X_test)\nyhat[0:5]\ntrain_score = metrics.accuracy_score(y_train, neigh.predict(X_train))\ntest_score = metrics.accuracy_score(y_test, yhat)\nprint(\"Train set Accuracy for \", k, \" is: \", train_score)\nprint(\"Test set Accuracy for \", k, \" is: \", test_score)\nprint(\"The Average for the two scores is: \", np.mean([train_score, test_score]))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "k = 7\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train.values.ravel())\nyhat = neigh.predict(X_test)\nyhat[0:5]\ntrain_score = metrics.accuracy_score(y_train, neigh.predict(X_train))\ntest_score = metrics.accuracy_score(y_test, yhat)\nprint(\"Train set Accuracy for \", k, \" is: \", train_score)\nprint(\"Test set Accuracy for \", k, \" is: \", test_score)\nprint(\"The Average for the two scores is: \", np.mean([train_score, test_score]))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "k = 8\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train.values.ravel())\nyhat = neigh.predict(X_test)\nyhat[0:5]\ntrain_score = metrics.accuracy_score(y_train, neigh.predict(X_train))\ntest_score = metrics.accuracy_score(y_test, yhat)\nprint(\"Train set Accuracy for \", k, \" is: \", train_score)\nprint(\"Test set Accuracy for \", k, \" is: \", test_score)\nprint(\"The Average for the two scores is: \", np.mean([train_score, test_score]))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "k = 9\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train.values.ravel())\nyhat = neigh.predict(X_test)\nyhat[0:5]\ntrain_score = metrics.accuracy_score(y_train, neigh.predict(X_train))\ntest_score = metrics.accuracy_score(y_test, yhat)\nprint(\"Train set Accuracy for \", k, \" is: \", train_score)\nprint(\"Test set Accuracy for \", k, \" is: \", test_score)\nprint(\"The Average for the two scores is: \", np.mean([train_score, test_score]))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "k = 10\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train.values.ravel())\nyhat = neigh.predict(X_test)\nyhat[0:5]\ntrain_score = metrics.accuracy_score(y_train, neigh.predict(X_train))\ntest_score = metrics.accuracy_score(y_test, yhat)\nprint(\"Train set Accuracy for \", k, \" is: \", train_score)\nprint(\"Test set Accuracy for \", k, \" is: \", test_score)\nprint(\"The Average for the two scores is: \", np.mean([train_score, test_score]))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Decision Tree"
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Solving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/Python36\n\n  added / updated specs: \n    - pydotplus\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2020.6.20  |       hecda079_0         145 KB  conda-forge\n    openssl-1.1.1g             |       h516909a_1         2.1 MB  conda-forge\n    pydotplus-2.0.2            |     pyhd1c1de3_3          23 KB  conda-forge\n    python_abi-3.6             |          1_cp36m           4 KB  conda-forge\n    certifi-2020.6.20          |   py36h9f0ad1d_0         151 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         2.4 MB\n\nThe following NEW packages will be INSTALLED:\n\n    pydotplus:       2.0.2-pyhd1c1de3_3 conda-forge\n    python_abi:      3.6-1_cp36m        conda-forge\n\nThe following packages will be UPDATED:\n\n    certifi:         2020.6.20-py36_0   anaconda    --> 2020.6.20-py36h9f0ad1d_0 conda-forge\n    openssl:         1.1.1g-h7b6447c_0  anaconda    --> 1.1.1g-h516909a_1        conda-forge\n\nThe following packages will be DOWNGRADED:\n\n    ca-certificates: 2020.7.22-0        anaconda    --> 2020.6.20-hecda079_0     conda-forge\n\n\nDownloading and Extracting Packages\nca-certificates-2020 | 145 KB    | ##################################### | 100% \nopenssl-1.1.1g       | 2.1 MB    | ##################################### | 100% \npydotplus-2.0.2      | 23 KB     | ##################################### | 100% \npython_abi-3.6       | 4 KB      | ##################################### | 100% \ncertifi-2020.6.20    | 151 KB    | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n"
                }
            ],
            "source": "from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.externals.six import StringIO\n!conda install -c conda-forge pydotplus\nimport matplotlib.image as mpimg\nfrom sklearn import tree\n%matplotlib inline "
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Decision's Tree Accuracy:  0.7476356092501067\n"
                }
            ],
            "source": "X_trainset, X_testset, y_trainset, y_testset = train_test_split(Z, Y, test_size=0.3, random_state=3)\ncollisionTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\ncollisionTree.fit(X_trainset, y_trainset)\npredTree = collisionTree.predict(X_testset)\nprint(\"Decision's Tree Accuracy: \", metrics.accuracy_score(y_testset, predTree))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "dot_data = StringIO()\nfilename = \"collisiontree.png\"\nfeatureNames = Z[0:43]\ntargetNames = dfm3[\"SEVERITYCODE\"].unique().tolist()\nout=tree.export_graphviz(collisionTree, feature_names = featureNames, out_file=dot_data, class_names= np.unique(y_trainset), filled=True,  special_characters=True,rotate=False)  \ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png(filename)\nimg = mpimg.imread(filename)\nplt.figure(figsize=(100, 200))\nplt.imshow(img,interpolation='nearest')"
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "0.7234743927640934\n0.7583745194947831\n0.4757728828062968\n"
                }
            ],
            "source": "from sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\nprint(f1_score(y_testset, yhat, average='weighted')) \nprint(jaccard_similarity_score(y_testset, yhat))\nprint(log_loss(y_testset, yhat_prob))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Logistic Regression"
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": "import pylab as pl\nimport scipy.optimize as opt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\nfrom sklearn.metrics import log_loss"
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:1: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n  if __name__ == '__main__':\n"
                },
                {
                    "data": {
                        "text/plain": "array([[-0.47276628, -0.18423131, -0.15992516,  0.04180368, -0.46978749,\n        -0.16032346, -0.10144727, -0.2829119 , -0.58639735, -0.18400078,\n        -0.46728901, -0.12485177,  3.10580262, -0.09528151, -0.6987066 ,\n        -0.26722193, -0.4095051 ,  1.10026244, -0.01815483, -0.01482254,\n        -1.17956994, -0.05095957, -0.42599318,  2.140536  , -0.01003431,\n        -0.02839133, -0.07437113, -0.27753595, -0.27192934, -0.26235327,\n        -1.38919074, -0.09108426, -0.01711623, -0.02052295, -0.08012637,\n        -0.0247708 ,  1.70528733, -0.08865212, -0.08121824,  1.67263443,\n        -0.11185001, -1.25617722, -0.18357502],\n       [ 1.31622514, -0.18423131, -0.15992516,  1.90000948, -0.46978749,\n        -0.16032346, -0.10144727, -0.2829119 ,  1.70532831, -0.18400078,\n        -0.46728901, -0.12485177, -0.32197796, -0.09528151, -0.6987066 ,\n        -0.26722193, -0.4095051 ,  1.10026244, -0.01815483, -0.01482254,\n        -1.17956994, -0.05095957,  2.34745543, -0.46717271, -0.01003431,\n        -0.02839133, -0.07437113, -0.27753595, -0.27192934, -0.26235327,\n         0.71984356, -0.09108426, -0.01711623, -0.02052295, -0.08012637,\n        -0.0247708 , -0.58641144, -0.08865212, -0.08121824, -0.59785927,\n        -0.11185001,  0.79606602, -0.18357502],\n       [-0.47276628, -0.18423131, -0.15992516,  0.04180368,  2.12862202,\n        -0.16032346, -0.10144727, -0.2829119 , -0.58639735, -0.18400078,\n        -0.46728901, -0.12485177, -0.32197796, -0.09528151,  1.43121592,\n        -0.26722193, -0.4095051 , -0.90887407, -0.01815483, -0.01482254,\n        -1.17956994, -0.05095957, -0.42599318,  2.140536  , -0.01003431,\n        -0.02839133, -0.07437113, -0.27753595, -0.27192934, -0.26235327,\n        -1.38919074, -0.09108426, -0.01711623, -0.02052295, -0.08012637,\n        -0.0247708 ,  1.70528733, -0.08865212, -0.08121824, -0.59785927,\n        -0.11185001,  0.79606602, -0.18357502],\n       [-0.47276628, -0.18423131, -0.15992516,  0.04180368,  2.12862202,\n        -0.16032346, -0.10144727, -0.2829119 , -0.58639735, -0.18400078,\n        -0.46728901, -0.12485177, -0.32197796, -0.09528151,  1.43121592,\n        -0.26722193, -0.4095051 , -0.90887407, -0.01815483, -0.01482254,\n        -1.17956994, -0.05095957, -0.42599318,  2.140536  , -0.01003431,\n        -0.02839133, -0.07437113, -0.27753595, -0.27192934, -0.26235327,\n        -1.38919074, -0.09108426, -0.01711623, -0.02052295, -0.08012637,\n        -0.0247708 ,  1.70528733, -0.08865212, -0.08121824, -0.59785927,\n        -0.11185001,  0.79606602, -0.18357502],\n       [-0.47276628, -0.18423131, -0.15992516,  0.04180368, -0.46978749,\n        -0.16032346, -0.10144727, -0.2829119 ,  1.70532831, -0.18400078,\n        -0.46728901, -0.12485177, -0.32197796, -0.09528151, -0.6987066 ,\n        -0.26722193, -0.4095051 ,  1.10026244, -0.01815483, -0.01482254,\n         0.8477666 , -0.05095957, -0.42599318, -0.46717271, -0.01003431,\n        -0.02839133, -0.07437113, -0.27753595, -0.27192934, -0.26235327,\n         0.71984356, -0.09108426, -0.01711623, -0.02052295, -0.08012637,\n        -0.0247708 , -0.58641144, -0.08865212, -0.08121824, -0.59785927,\n        -0.11185001,  0.79606602, -0.18357502]])"
                    },
                    "execution_count": 35,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "Z = preprocessing.StandardScaler().fit(Z).transform(Z)\nZ[0:5]"
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train set: (87408, 43) (87408, 1)\nTest set: (21852, 43) (21852, 1)\n"
                }
            ],
            "source": "X_train, X_test, y_train, y_test = train_test_split(Z, Y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)"
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n          tol=0.0001, verbose=0, warm_start=False)"
                    },
                    "execution_count": 37,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train, y_train.values.ravel())\nLR"
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 1, 1, ..., 1, 1, 1])"
                    },
                    "execution_count": 38,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "yhat = LR.predict(X_test)\nyhat"
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[0.64586581, 0.35413419],\n       [0.65139539, 0.34860461],\n       [0.51067638, 0.48932362],\n       ...,\n       [0.83549529, 0.16450471],\n       [0.58674544, 0.41325456],\n       [0.69694481, 0.30305519]])"
                    },
                    "execution_count": 39,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "yhat_prob = LR.predict_proba(X_test)\nyhat_prob"
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.7583745194947831"
                    },
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "jaccard_similarity_score(y_test, yhat)"
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[[14543     0]\n [    0     0]]\n"
                }
            ],
            "source": "def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\nprint(confusion_matrix(y_test, yhat, labels=[1,0]))"
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Confusion matrix, without normalization\n[[14543     0]\n [    0     0]]\n"
                },
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 2 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\nnp.set_printoptions(precision=2)\n\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Confusion matrix')"
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "              precision    recall  f1-score   support\n\n           1       0.76      0.95      0.85     15331\n           2       0.72      0.31      0.43      6521\n\n   micro avg       0.76      0.76      0.76     21852\n   macro avg       0.74      0.63      0.64     21852\nweighted avg       0.75      0.76      0.72     21852\n\n0.4757728828062968\n"
                }
            ],
            "source": "print(classification_report(y_test, yhat))\nprint(log_loss(y_test, yhat_prob))"
        },
        {
            "cell_type": "code",
            "execution_count": 156,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "LogLoss: : 0.48\n"
                }
            ],
            "source": "LR2 = LogisticRegression(C=0.01, solver='sag').fit(X_train, y_train.values.ravel())\nyhat_prob2 = LR2.predict_proba(X_test)\nprint (\"LogLoss: : %.2f\" % log_loss(y_test, yhat_prob2))"
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "0.7234743927640934\n0.7583745194947831\n0.4757728828062968\n"
                }
            ],
            "source": "from sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\nprint(f1_score(y_test, yhat, average='weighted')) \nprint(jaccard_similarity_score(y_test, yhat))\nprint(log_loss(y_test, yhat_prob))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Support Vector Machine"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn import svm\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools"
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train set: (87408, 43) (87408, 1)\nTest set: (21852, 43) (21852, 1)\n"
                }
            ],
            "source": "X_trainSVM, X_testSVM, y_trainSVM, y_testSVM = train_test_split(Z, Y, test_size=0.2, random_state=4)\nprint ('Train set:', X_trainSVM.shape,  y_trainSVM.shape)\nprint ('Test set:', X_testSVM.shape,  y_testSVM.shape)"
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n"
                },
                {
                    "data": {
                        "text/plain": "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n  shrinking=True, tol=0.001, verbose=False)"
                    },
                    "execution_count": 51,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "clf = svm.SVC(kernel='rbf')\nclf.fit(X_trainSVM, y_trainSVM.values.ravel()) "
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 1, 1, 1, 1])"
                    },
                    "execution_count": 52,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "yhatSVM = clf.predict(X_testSVM)\nyhatSVM [0:5]"
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [
                {
                    "ename": "AttributeError",
                    "evalue": "predict_proba is not available when  probability=False",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-46-bb4036caeab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myhat_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \"\"\"\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[1;32m    586\u001b[0m                                  \" probability=False\")\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'c_svc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nu_svc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
                    ]
                }
            ],
            "source": "yhat_probSVM = clf.predict_proba(X_testSVM)"
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "0.7173579125834395\n0.757550796265788\n"
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'yhat_probSVM' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-53-1fc309624ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_testSVM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhatSVM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaccard_similarity_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_testSVM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhatSVM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_testSVM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat_probSVM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m: name 'yhat_probSVM' is not defined"
                    ]
                }
            ],
            "source": "from sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\nprint(f1_score(y_testSVM, yhatSVM, average='weighted')) \nprint(jaccard_similarity_score(y_testSVM, yhatSVM))\nprint(log_loss(y_testSVM, yhat_probSVM))"
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[[14699     0]\n [    0     0]]\n"
                }
            ],
            "source": "def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\nprint(confusion_matrix(y_testSVM, yhatSVM, labels=[1,0]))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}